{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#import os\n",
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "#import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mustard++_text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch labeled data instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = []\n",
    "\n",
    "list_of_text = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['Sarcasm'] in [0.0, 1.0]:\n",
    "      text = row['SENTENCE']\n",
    "      text = re.sub(\"[\\n]\", \" \", text)\n",
    "      list_of_text.append(text)\n",
    "\n",
    "      tmp = {'key': row['SCENE'], \n",
    "             'image': row['KEY'], \n",
    "             'text': list_of_text,\n",
    "             'label': row['Sarcasm']}\n",
    "\n",
    "      data_dict.append(tmp)\n",
    "      list_of_text = []\n",
    "    else:\n",
    "      text = row['SENTENCE']\n",
    "      text = re.sub(\"[\\n]\", \" \", text)\n",
    "      list_of_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_dict:\n",
    "  i['label'] = int(i['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess valid data instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_frame(frame):\n",
    "    return frame is not None and frame.size > 0\n",
    "\n",
    "failed_data_points = []\n",
    "\n",
    "videos = []\n",
    "text = []\n",
    "labels = []\n",
    "ids = []\n",
    "\n",
    "down_width = 384\n",
    "down_height = 224\n",
    "down_points = (down_width, down_height)\n",
    "\n",
    "num_frames = 16\n",
    "for data in data_dict[:]:\n",
    "    video_id = data['image']\n",
    "    video_path = 'videos/final_utterance_videos/'+video_id+'.mp4'\n",
    "    cam = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # skip data point which are shorter than num_frames\n",
    "    if total_frames < num_frames:\n",
    "        failed_data_points.append(video_path)\n",
    "        continue\n",
    "\n",
    "    random_frame_idxs = random.sample(range(total_frames), num_frames)\n",
    "\n",
    "    frames = []\n",
    "    for idx, frame_idx in enumerate(sorted(random_frame_idxs)):\n",
    "        valid_frame = False\n",
    "        attempts = 0 \n",
    "        \n",
    "        while not valid_frame and attempts < 3:\n",
    "            cam.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "            ret, frame = cam.read()\n",
    "\n",
    "            if ret and is_valid_frame(frame):\n",
    "                resized_frame = cv2.resize(frame, down_points, interpolation=cv2.INTER_LINEAR)\n",
    "                frames.append(resized_frame)\n",
    "                valid_frame = True\n",
    "            else:\n",
    "                attempts += 1\n",
    "                if frame_idx < total_frames - 1:\n",
    "                    frame_idx += 1\n",
    "                else:\n",
    "                    frame_idx -= 1\n",
    "\n",
    "    # if any frames are corrupted, skip data point\n",
    "    if len(frames) < num_frames:\n",
    "        failed_data_points.append(video_path)\n",
    "        continue\n",
    "\n",
    "    # print(f'video: {video_id}, frames {len(frames)}')\n",
    "\n",
    "    video = np.array(frames)\n",
    "    tensor_video = torch.from_numpy(video)\n",
    "    videos.append(tensor_video)\n",
    "\n",
    "    text.append(data['text'])\n",
    "    labels.append(data['label'])\n",
    "    ids.append(data['key'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] in ['BBT', 'SV']:\n",
    "        train_data.append(row['SCENE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video = []\n",
    "train_text = []\n",
    "train_label = []\n",
    "train_id = []\n",
    "rest_videos = []\n",
    "rest_text = []\n",
    "rest_labels = []\n",
    "rest_ids = []\n",
    "\n",
    "for index, id in enumerate(ids):\n",
    "    if id in train_data:\n",
    "        train_video.append(videos[index])\n",
    "        train_text.append(text[index])\n",
    "        train_label.append(labels[index])\n",
    "        train_id.append(ids[index])\n",
    "    else:\n",
    "        rest_videos.append(videos[index])\n",
    "        rest_text.append(text[index])\n",
    "        rest_labels.append(labels[index])\n",
    "        rest_ids.append(ids[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text, test_text, val_video, test_video, val_label, test_label, val_id, test_id = train_test_split(rest_text, rest_videos, rest_labels, rest_ids, test_size=0.5, stratify=rest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_video, f\"preprocessed/video_train_holdout.pt\")\n",
    "torch.save(train_text, f\"preprocessed/text_train_holdout.pt\")\n",
    "torch.save(train_label, f\"preprocessed/labels_train_holdout.pt\")\n",
    "torch.save(train_id, f\"preprocessed/ids_train_holdout.pt\")\n",
    "\n",
    "torch.save(val_video, f\"preprocessed/video_val_holdout.pt\")\n",
    "torch.save(val_text, f\"preprocessed/text_val_holdout.pt\")\n",
    "torch.save(val_label, f\"preprocessed/labels_val_holdout.pt\")\n",
    "torch.save(val_id, f\"preprocessed/ids_val_holdout.pt\")\n",
    "\n",
    "torch.save(test_video, f\"preprocessed/video_test_holdout.pt\")\n",
    "torch.save(test_text, f\"preprocessed/text_test_holdout.pt\")\n",
    "torch.save(test_label, f\"preprocessed/labels_test_holdout.pt\")\n",
    "torch.save(test_id, f\"preprocessed/ids_test_holdout.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Sarcasm'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBT = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] == 'BBT':\n",
    "        BBT.append(row)\n",
    "\n",
    "bbt_df = pd.DataFrame(BBT)\n",
    "\n",
    "SV = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] == 'SV':\n",
    "        SV.append(row)\n",
    "\n",
    "sv_df = pd.DataFrame(SV)\n",
    "\n",
    "FRIENDS = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] == 'FRIENDS':\n",
    "        FRIENDS.append(row)\n",
    "\n",
    "friends_df = pd.DataFrame(FRIENDS)\n",
    "\n",
    "GOLDENGIRLS = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] == 'GOLDENGIRLS':\n",
    "        GOLDENGIRLS.append(row)\n",
    "\n",
    "golden_df = pd.DataFrame(GOLDENGIRLS)\n",
    "\n",
    "SARCASMOHOLICS = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['SHOW'] == 'SARCASMOHOLICS':\n",
    "        SARCASMOHOLICS.append(row)\n",
    "\n",
    "sar_df = pd.DataFrame(SARCASMOHOLICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_friends, rest_friends = train_test_split(friends_df, test_size=0.3, stratify=friends_df['Sarcasm'])\n",
    "test_friends, val_friends = train_test_split(rest_friends, test_size=0.5, stratify=rest_friends['Sarcasm'])\n",
    "\n",
    "train_bbt, rest_bbt = train_test_split(bbt_df, test_size=0.3, stratify=bbt_df['Sarcasm'])\n",
    "test_bbt, val_bbt = train_test_split(rest_bbt, test_size=0.5, stratify=rest_bbt['Sarcasm'])\n",
    "\n",
    "train_sv, rest_sv = train_test_split(sv_df, test_size=0.3, stratify=sv_df['Sarcasm'])\n",
    "test_sv, val_sv = train_test_split(rest_sv, test_size=0.5, stratify=rest_sv['Sarcasm'])\n",
    "\n",
    "train_golde, rest_golde = train_test_split(golden_df, test_size=0.3)\n",
    "test_golde, val_golde = train_test_split(rest_golde, test_size=0.5)\n",
    "\n",
    "train_sarc, rest_sarc = train_test_split(sar_df, test_size=0.5)\n",
    "test_sarc, val_sarc = train_test_split(rest_sarc, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for index, row in train_friends.iterrows():\n",
    "    train_data.append(row['SCENE'])\n",
    "for index, row in train_golde.iterrows():\n",
    "    train_data.append(row['SCENE'])\n",
    "for index, row in train_sarc.iterrows():\n",
    "    train_data.append(row['SCENE'])\n",
    "for index, row in train_bbt.iterrows():\n",
    "    train_data.append(row['SCENE'])\n",
    "for index, row in train_sv.iterrows():\n",
    "    train_data.append(row['SCENE'])\n",
    "\n",
    "\n",
    "val_data = []\n",
    "for index, row in val_friends.iterrows():\n",
    "    val_data.append(row['SCENE'])\n",
    "for index, row in val_golde.iterrows():\n",
    "    val_data.append(row['SCENE'])\n",
    "for index, row in val_sarc.iterrows():\n",
    "    val_data.append(row['SCENE'])\n",
    "for index, row in val_bbt.iterrows():\n",
    "    val_data.append(row['SCENE'])\n",
    "for index, row in val_sv.iterrows():\n",
    "    val_data.append(row['SCENE'])\n",
    "\n",
    "test_data = []\n",
    "for index, row in test_friends.iterrows():\n",
    "    test_data.append(row['SCENE'])\n",
    "for index, row in test_golde.iterrows():\n",
    "    test_data.append(row['SCENE'])\n",
    "for index, row in test_sarc.iterrows():\n",
    "    test_data.append(row['SCENE'])\n",
    "for index, row in test_bbt.iterrows():\n",
    "    test_data.append(row['SCENE'])\n",
    "for index, row in test_sv.iterrows():\n",
    "    test_data.append(row['SCENE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_video = []\n",
    "train_text = []\n",
    "train_label = []\n",
    "train_id = []\n",
    "\n",
    "val_video = []\n",
    "val_text = []\n",
    "val_label = []\n",
    "val_id = []\n",
    "\n",
    "test_video = []\n",
    "test_text = []\n",
    "test_label = []\n",
    "test_id = []\n",
    "\n",
    "\n",
    "for index, id in enumerate(ids):\n",
    "    if id in train_data:\n",
    "        train_video.append(videos[index])\n",
    "        train_text.append(text[index])\n",
    "        train_label.append(labels[index])\n",
    "        train_id.append(ids[index])\n",
    "    elif id in val_data:\n",
    "        val_video.append(videos[index])\n",
    "        val_text.append(text[index])\n",
    "        val_label.append(labels[index])\n",
    "        val_id.append(ids[index])\n",
    "    elif id in test_data:\n",
    "        test_video.append(videos[index])\n",
    "        test_text.append(text[index])\n",
    "        test_label.append(labels[index])\n",
    "        test_id.append(ids[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_video, f\"preprocessed/video_train_stratified.pt\")\n",
    "torch.save(train_text, f\"preprocessed/text_train_stratified.pt\")\n",
    "torch.save(train_label, f\"preprocessed/labels_train_stratified.pt\")\n",
    "torch.save(train_id, f\"preprocessed/ids_train_stratified.pt\")\n",
    "\n",
    "torch.save(val_video, f\"preprocessed/video_val_stratified.pt\")\n",
    "torch.save(val_text, f\"preprocessed/text_val_stratified.pt\")\n",
    "torch.save(val_label, f\"preprocessed/labels_val_stratified.pt\")\n",
    "torch.save(val_id, f\"preprocessed/ids_val_stratified.pt\")\n",
    "\n",
    "torch.save(test_video, f\"preprocessed/video_test_stratified.pt\")\n",
    "torch.save(test_text, f\"preprocessed/text_test_stratified.pt\")\n",
    "torch.save(test_label, f\"preprocessed/labels_test_stratified.pt\")\n",
    "torch.save(test_id, f\"preprocessed/ids_test_stratified.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
