{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize sarcasm headlines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./Sarcasm_Headlines_Dataset.json', lines=True)\n",
    "#df.to_csv('./headlines.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_sarcastic'].value_counts().plot(kind='pie', autopct='%.2f%%', explode=[0.05, 0])\n",
    "\n",
    "# 1 : sarcastic\n",
    "# 0 : not sarcastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['article_link'], axis=1)\n",
    "df.drop_duplicates(subset=['headline'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-process dataset [clean stemmwords, remove stopwords, etc.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from unidecode import unidecode\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = df['headline']\n",
    "df['headline'] = df['headline'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x.lower()))\n",
    "df['headline'] = df['headline'].apply(lambda x: re.sub('\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "df['headline'] = df['headline'].apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x.lower()) if word not in stop_words]))\n",
    "df['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in origin:\n",
    "    words.extend(text.split())\n",
    "word_count = collections.Counter(words)\n",
    "top_words = dict(word_count.most_common(10))\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.bar(range(len(top_words)), list(top_words.values()), align='center')\n",
    "plt.xticks(range(len(top_words)), list(top_words.keys()))\n",
    "plt.grid(alpha = 0.5)\n",
    "plt.title('ten most used words before cleaning', fontsize = 18)\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in df['headline']:\n",
    "    words.extend(text.split())\n",
    "word_count = collections.Counter(words)\n",
    "top_words = dict(word_count.most_common(10))\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.bar(range(len(top_words)), list(top_words.values()), align='center')\n",
    "plt.xticks(range(len(top_words)), list(top_words.keys()))\n",
    "plt.grid(alpha = 0.5)\n",
    "plt.title('ten most used words after cleaning', fontsize = 18)\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./headlines.csv', index=False)\n",
    "df.to_json('./headlines.json', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target = 'is_sarcastic', train_size=0.8, valid_size=0.1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame().assign(headline=X_train, is_sarcastic=y_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame().assign(headline=X_test, is_sarcastic=y_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.DataFrame().assign(headline=X_valid, is_sarcastic=y_valid)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./headlines_train.csv', index=False)\n",
    "df_test.to_csv('./headlines_test.csv', index=False)\n",
    "df_valid.to_csv('./headlines_valid.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
